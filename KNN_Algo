import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#reading the data and applying slicing and dicing
dataset = pd.read_csv("sal.csv", names = ["age","workclass","fnlwgt","education","educational-nul",
                                          "marital-status","ocupation","realtionship","race",
                                          "sex","capital-gain","capital-loss","hours-per-week",
                                          "native-country","salary"])
X= dataset.iloc[:,0:14].values
y= dataset.iloc[:,-1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)


#replacing missing(NaN) values with the median
#from sklearn.preprocessing import Imputer
#imputer = Imputer(missing_values='NaN', strategy='median', axis=0)
#imputer.fit(X[:,[0,2,4,10,11,12]])
#X[:,[0,2,4,10,11,12]]=imputer.transform(X[:,[0,2,4,10,11,12]])


#encoding the categorical values
#from sklearn.preprocessing import LabelEncoder
#labelencoder_X = LabelEncoder()
#X[:,[1,3,5,6,7,8,9,13]]=labelencoder_X.fit_transform(X[:,[1,3,5,6,7,8,9,13]])

#labelencoder_y=LabelEncoder()
#y=labelencoder_y.fit_transform(y)

#Dummy variable encoding and sparse matrix creation
#from sklearn.preprocessing import OneHotEncoder
#onehotencoder=OneHotEncoder(categorical_features=[0])
#X=onehotencoder.fit_transform(X)
#X=X.toarray()

#Applying feature scaling to get the data on similar scale
#from sklearn.preprocessing import StandardScaler
#sc= StandardScaler()
#X=sc.fit_transform(X)

#creating scatter plot
#from pandas.plotting import scatter_matrix
#dataset.hist(bins=30)
#scatter_matrix(dataset, alpha=1.0)

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbours = 11)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
